1. #### 你用redis来干啥？

做缓存提高效率，过期机制，分布式锁

缓存：redis的读写性能优异，所以有些高频查询或者是流量高峰期的查询，如果直接查询传统的关系型数据库速度慢，并且压力大的时候很容易把数据库拖垮。

过期机制：存储一段时间内有效的数据，例如短信验证码这种，使用redis过期机制，无需使用方关心过期数据清理

分布式锁：利用redis是单线程的特性，应对高并发的系统，都是用的多服务器部署，传统的数据锁处理方式只能针对本服务器线程，redis 使用 setnx 尝试设置key ，设置key 的同时必须同时设置过期时间，不然可能造成锁永远不释放 。锁变量的值加上客户端的唯一标识区分不同的客户端加锁操作。解锁操作需要用到lua脚本，涉及两步原子操作，读锁变量，释放锁，无法用一个命令完成。高可靠的redis分布式锁 RedLock 分布式锁算法，依次想N个客户端发送加锁请求，超过一半的实例加锁成功才是真正的加锁成功。

2. #### redis 的数据结构有哪些？

String Hash List Set SortedSet  (HyperLogLog,Geo,Pub/Sub, Redis Module(BloomFilter RedisSearch Redis-ML))

BitMap 按位存储信息，可以来实现布隆过滤器。 hyperLoglog 供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV； geospatial 可以用来保存地理位置，并坐位置距离计算或者根据半径计算位置，（redis实现附近的人）

3. #### 缓存击穿，缓存穿透，缓存雪崩是怎么回事？

缓存穿透：缓存和数据库中都没有的数据，而用户频繁发起这种请求，导致数据库压力过大，严重时会击垮数据库。解决方案：1）接口层加上校验，比如参数校验，用户鉴权，不合法直接pass；2）还可以将无数据的key的值缓存为null；3）对单个ip或者单个用户在每秒访问次数做限制，超过的都拉黑；4）redis的高级用法，布隆过滤器，这个可以很好的防止缓存穿透的发生，原理是用高效的数据结构和算法快速判断这个key是否在数据库中存在，不存在直接return就行，存在再去查询db。

缓存击穿：和缓存雪崩有点像，但是击穿指的是一个key非常热点，在不停的扛着大量并发请求，当这个key失效时，就会直接请求数据库。解决方案：设置热点数据永不过期，或者加上互斥锁也可以。

缓存雪崩：大量的key过期时间设置过于集中，到了过期那个时间点，刚好有大量的请求直接查询数据库，导致数据库压力过大直接崩溃，数据库重启又立马被新的流量打死。解决方案：在批量往redis中存数据的时候把每个key的失效时间加上一个随机值，保证数据不会在同一时刻出现大面积失效。最好将热点数据打散在集群的不同实例上，服务限流熔断降级。

4. #### keys与 scan 查询已 XXX 固定开头的key有什么区别？

keys 是一次性查询出来，数据准确，但是因为redis是单线程的，keys会导致线程阻塞一段时间，此时如果redis正在提供线上服务，会造成卡顿现象，直到这个命令执行完成。使用scan可以无阻塞提取，但是会有一定的重复概率，客户端需要去重。

5. #### redis 做异步队列

使用list作队列，lpush/rpush生产消息，lpop/rpop 消费消息，pop的阻塞版本是 blpop/brpop

subscribe 频道  publish 频道 内容。 消费者需要独占一个redis链接，一旦消费者下线，消息就会丢失

延时队列 使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理

6. #### redis是如何做持久化的，服务主从数据怎么交互？

AOF日志

- 保存的是具体执行的命令。
- 写后日志，好处避免额外的检查开销，执行过的命令一定是正确的。不会阻塞当前写操作。因为是写后日志。
- 风险点：在执行完命令后，立马宕机，存在丢失数据的风险。另外可能阻塞下一个操作，因为AOF日志也是在主线程中完成的。三种刷盘策略：always，同步刷盘；everysec，每秒刷盘；no，由操作系统控制合适时机刷盘；
- AOF太大：AOF重写机制，将重复的写命令合并后只记录最后一条。AOF重写是在某时刻根据Redis数据库现状创建一个新的AOF文件，即读取库中所有的键值对，生成一条插入命令。重写过程是由后台子线程来完成的，主线程fork出一个子线程。子线程会拷贝父进程的页表，不是物理内存。此时父子线程都共享一块物理内存。如果此时父进程未发生写操作，那父子进程会一直共享这块物理内存。写时复制机制：一旦父进程对某个数据进行修改，会对这块内存重新拷贝一个内存页，然后通过原来的内存页映射替换成新的物理地址进行写入。在此过程中，新的写操作，会记录到原AOF的缓冲区。而新的AOF日志缓冲区也会被记录，等所有的拷贝执行完，再将此缓存区中也执行完。最后用新的AOF文件替代旧的。

RDB快照

- 全量快照：数据量越多，快照就越大，往磁盘上写数据的时间开销就越大。
- save（阻塞），bgsave（后台，不阻塞）
- bgsave 写时复制策略。主进程fork出子进程，子进程开始读取主线程的内存数据，写入RDB文件。如果主线程有写操作。主线程会拷贝这块数据生成一个新的数据副本，子进程也会把这部分数据写入RDB文件
- 增量快照：在上一次快照的基础上，或许只对修改的数据进行快照记录，减少开销。

Redis 有两种持久化方案，RDB （Redis DataBase）快照和 AOF （Append Only File）文件。RDB做镜像全量备份，AOF做增量持久化。Redis 4.0 提倡两者搭配使用。因为RDB会耗时较长时间，不够实时，在停机的时候会导致大量的数据丢失，所以需要AOF来配合使用，在redis重启时候，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态，需要手动开启，AOF默认每秒持久化一次数据，所以如果断点最对多丢失1s的数据。RDB 是redis创建子线程与父线程共享数据段，父进程继续提供读写服务。恢复数据时比AOF快。AOF每1秒以追加的方式写数据，少了很多磁盘寻址的开销，写入性能好。缺点是文件比RDB大。使用AOF比使用RDB支持写的qps要低，因为每秒还要异步刷盘日志。一般两者一起使用。

7. #### redis 高效操作Pipeline

pipeline 可以将多次IO返回的时间缩减为一次，前提是pipeline执行的指令之间没有相关性。

8. #### redis 高可用架构？

##### 切片集群

解决数据量太多了，内存不够用了。需要扩展了。

纵向扩展：提升机器内存，cpu，磁盘。实施方便。有两点局限性；1）受限于机器硬件资源影响。2）如果单机数据量太大做RDB快照时，fork子进程的时间是随着数据量的增加而增加的。

横向扩展：使用多个redis实例，将数据分散在不同的实例上进行存储。在百万级，千万级的数据规模时，横向扩展的redis切片集群是一个非常不错的选择。redis 3.0 之前没有提供横向扩展的方案。redis cluster 从3.0官方提出。

redis cluster 

- 一个切片集群共有16384个哈希槽。正常情况下每个redis实例会平分所有的哈希槽（当实例配置不同，可手动设置槽位）。这个是在集群启动时完成的。
- 具体的数据映射方法是，将key按照CRC16算法计算得到一个16bit的值，然后用这个16bit的值对16383取模，得到所在的哈希槽位置。
- 客户端定位数据。每个实例会把自己获得到的哈希槽路由表发送给与它相连的集群节点。所以最后每个节点都有缓存所有哈希槽的路由表。客户端和集群建立连接后，redis实例就会把哈希槽路由表发送给客户端。客户端在本地也缓存这部分数据。当客户端请求键值对时，就知道去哪个实例上去请求数据了。
- 哈希槽路由表变更（增减实例，重新负载均衡）。redis实例之间通过之前的方式进行相互传递，更新哈希槽路由表信息，但是客户端无法感知。使用的是一种重定向机制来解决的。当客户端请求的键值对发生迁移，redis实例会返回一个moved 并带上哈希槽转移后的地址，客户端会重新通过这个地址来请求，并且会将客户端本地缓存的哈希槽路由表更新。如果此时刚好这个哈希槽处于迁移中的状态，客户端会受到 ASK 加上转移后的地址。此时客户端需要先向新实例发送一个asking命令，实例允许客户端操作时，再发送具体请求，但是不会更新本地哈希槽缓存。
- 为什么要用哈希槽，不直接用key路由到实例。由于cluster是去中心化，每个节点都有全量路由信息。这会造成路由表极其庞大，在客户端与服务端占很大的内存。另外在数据迁移时也会有很高的维护成本。集群中相邻节点进行路由表交换时也增加了网络资源的消耗，影响效率。
- 3.0之前的切片集群解决方案综述及与redis cluster对比
  - 数据路由：redis cluster 是需要客户端配合服务端进行使用，所以对应的SDK要升级到集群版才支持。其它的集群方案如twemproxy、codeis 都是中心化模式（增加proxy层）proxy层完成了路由的转发，对客户端友好，当然增加一层proxy会带来一定的性能损耗。
  - 数据迁移：twemproxy不支持在线扩容，需要停机做数据重新分配。redis cluster 和 codeis 都支持在线扩容。需要客户端重定向访问。因此在扩容期间，访问延迟会增加。redis cluster 会在各个节点更新路由表并且客户端也会同步更新，而codies 会在proxy层更新路由表。redis cluster 在数据迁移时同步的，会影响源节点和目标节点，迁移过程会有性能问题，codies 提供了异步迁移的方案，迁移速度更快，性能影响更小，但实现方案也比较复杂

##### 哨兵集群

redis sentinal 着眼于高可用，在master宕机时候，会自动将slave提升为master，继续提供服务。经典的哨兵集群，是至少3个结点的，如果只有两个节点，其中一个挂了，只剩一个哨兵无法完成转移。哨兵在进行主从切换时，读请求可以从slave上读取不受影响，写请求会失败。完成后主动通知客户端，客户端也需有机制定时从哨兵获取主库地址，防止通知丢失。

哨兵工作机制

- 通过pub/sub机制完成哨兵集群的构建，每个哨兵都会和主库建立连接，在主库上发布和订阅消息。
- 通过INFO命令从主库获取所有的从库列表。
- 通过pub/sub机制对客户端进行事件通知。
- 哨兵的leader选举，由此哨兵执行故障转移以及通知。leader选举的两个条件，得到半数以上的投票，票数大于哨兵配置文件中的quorum。具体的做法是使用类似raft的共识算法完成。具体过程是，当其中一个哨兵判断主库下线了，就会给其它的哨兵发送（is-master-down-by-addr）命令，接到命令的哨兵则会根据自身情况判断哨兵是否下线来回应支持(Y)或者反对（N）。如果某个哨兵收到的一半以上确认投票，会立即给自己leader选举投一票，并且把想成为leader的投票请求发给其它节点。收到leader投票的节点如果还未投票，则会投一票赞成。最先满足leader选举的两个条件的哨兵成为leader，执行故障转移。低概率存在每个哨兵都给自己投一票，满足这个条件的前提是，所有哨兵（哨兵探测到主库下线->向其它节点确认下线->leader选举给自己投票) 这个过程时间相等。而实际情况是，每个哨兵在定时进行主从库状态监测时候，每个哨兵会在固定周期上加置一个随机时间，目的就是破坏上述探测到确认到选举的时间相等。
- 如果哨兵集群中只有两个节点，此时必须获得的是2票。所以此时有个哨兵挂掉，一个哨兵是无法完成选举的。 

哨兵组件的主要功能

- 集群监控：负责master-slave是否正常工作，使用ping命令网络是否超时，少数服从多数。
- 重新选主：如果master挂了，则自动转移到slave上。
  1. 去除不符合规则的slave：通过和主库的超时次数决定，有一个阈值决定，超过阈值的次数就表示不满足条件，网络不好。
  2. 依次判断slave的从库优先级，从库复制主库的进度，从库的ID号选择。
- 消息通知：让从库与新的主库进行同步，通知客户端，与新的主库连接。

9. #### reids为什么快？

和传统的关系型数据库相比，关系型数据库数据存储是在硬盘上，每次数据库IO直接与磁盘打交道成本较高，而redis是基于内存的采用的是单线程模型的kv数据库，绝大部分请求是纯粹的内存操作，非常快速，其数据结构类似于HashMap 查询和操作的时间复杂度都是O(1)。采用的是单线程，避免的不必要的上下文切换和竞争条件，也不存在多进程或者多线程切换导致cpu的消耗，不用考虑各种锁的问题。线程模型采用的是多路I/O复用模型，非阻塞IO。单线程无法发挥服务器的多核优势，单机器开多个redis实例。

不使用memcache 1) key 不能超过 250 个字节；

2) value 不能超过 1M 字节；

3) key 的最大失效时间是 30 天；

4) 只支持 K-V 结构，不提供持久化和主从同步功能。

10. #### redis如何进行的主从同步？

启动一台slave的时候，会发送一个psync命令给master，如果这个slave第一次连接到master则会触发一个全量复制。master就会启动一个线程，生成rdb快照，还会把最新的请求就缓存在内存中，rdb文件生成后，master会将这个rdb发送给slave，slave拿到之后第一件事就是写入本地磁盘，然后加载到内存，然后master会把内存中缓存的新命令都会发送给salve。

主从同步网络中断：主库在断网期间将操作命令写入一个环形缓冲区，主库会记录自己写的位置，从库会记录自己读的位置。所以会存在从库还没读取到数据，主库会用新数据覆盖旧数据。等到网络恢复时，从库会发送psync命令给主库，把自己当前同步的偏移量发送给主库，主库根据这个偏移量确认从什么地方开始同步数据。

11. #### redis的过期key删除策略

定期删除+惰性删除

定期删除：默认100ms就随机抽一些设置过期时间的key，检查是否过期，过期了就删除，扫描全部的代价太大。

惰性删除：等到重新查询到这个key的时候判断key是否过期，过期了就删除。

内存淘汰机制：如果定期没删，也没查询到，这个时候，等到redis可以使用空间越来越少，就会触发内存淘汰机制来清理空间。LRU:回收最少使用的key（所有/过期集合）；random：随机回收key（所有/过期集合）ttl:在过期的集合key中优先回收存活时间较短的key。不使用真实的LRU算法是因为LRU算法太耗费内存了。

12. #### redis 与 mysql 双写的数据一致性问题

- 读写缓存：采用同步写会策略则可保证缓存与数据库数据一致
- 只读缓存：要具体根据先删缓存还是先更新数据库来分析问题

| 操作顺序 | 是否有并发读请求 | 潜在问题                                       | 现象                                                         | 应对方案                                                     |
| -------- | ---------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 先删后改 | 否               | 删除成功，修改失败                             | 数据库中读到的是旧数据                                       | mq标记key更新最终值，直到修改成功，才删除mq中的记录，否则一直重试 |
| 先删后改 | 是               | 删除成功，更新操作未完成，有并发读             | 并发读请求到是数据库中的旧数据，并且会把旧数据更新到缓存，导致缓存一直是旧数据 | 延迟双删：在第一次删除缓存后，再延迟一段时间进行一次删除（时间需根据实际情况统计确定） |
| 先改后删 | 是               | 数据库更新成功，缓存删除尚未完成，有并发读操作 | 并发请求从缓存中读取旧的数据                                 | 等待缓存删除完成，此案例影响范围小，会有一小段时间，暂无很好处理方案 |
| 先改后删 | 否               | 数据库更新成功，缓存删除失败                   | 应用从缓存读到旧数据                                         | 重试缓存删除：同样mq记录最终修改值，直到删除成功，mq中才把相应记录删除，否则一直重试 |

只要是用到缓存就一定会存在双存储双写一致性问题，如果严格要求数据库和缓存数据一致性，那就读请求和写请求都要串行化，串到一个内存队列中，串行化可以保证一定不会出现不一致的情况，但是也会导致系统的吞吐量大幅度降低。一般是主动更新db后一步更新redis失败，如果对服务耗时不敏感则直接加入重试机制，如果敏感则异步任务补偿失败的。

13. #### redis的线程模型

redis内部使用文件事件处理器（file event handler），这个文件处理器是单线程的，所以redis才叫做单线程模型，它采用IO多路复用机制同时监听多个Socket，根据Socket上的事件来选择对应的事件处理器进行处理。文件事件处理器结构包括4部分：多个socket，IO多路复用程序，文件事件分排器，事件处理器。多个socket可能会并发产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，会将socket产生的事件放入队列中排队，事件分排器每次从队列中取出一个事件，把该事件交给对应的事件处理器来处理。

14. #### Redis 做缓存的两种模式

- 只读缓存：应用程序获取数据的时候，先调用redis的get接口，查询数据是否存在。所有的写请求会发送到服务器后端，并且把Redis中缓存的key删除。
- 读写缓存：读写请求都会发送到缓存处理，最新的数据是在redis中。有同步和异步两种方式同步到磁盘。

15. #### Redis高可用集群脑裂及方案

- 主库假故障（主库所在的机器CPU飙升，或者IO慢，导致和从库，哨兵通信短时间异常，会被判断客观下线），哨兵会发起主库迁移，但是原主库后又恢复上线，执行“一系列修改操作1”。这下就会导致出现两个主库。随后哨兵会给原主库发送命令slave of 新主库，此时会触发全量同步，加载新主库的RDB文件，从而会将“一系列修改操作1”丢失。
- 解决方案：通过两个集群参数 min-slaves-to-wirte, min-slaves-max-lag 预防脑裂。例如分别设置为 5,15 表示如果有5个或者以上的从库和主库进行ACK消息延迟超过15秒，就禁止主库接收客户端写请求。

16. #### Redis 秒杀场景的支持

- 秒杀前：页面静态化，cdn部署，此阶段不需要用到redis。恶意请求的拦截。
- 秒杀中：库存查验，库存扣减，订单处理。库存查验与库存扣减都需要在redis中进行，而且还需要保证原子性，一般使用lua脚本实现，也可以是用分布式锁来实现，先获取分布式锁再做后面两步操作。订单处理，已经是写场景，请求量没那么多，数据库可以承载下来，还有就是订单处理需要用到各种其他的数据。订单异常重试。
- 秒杀后：已经不需要。

